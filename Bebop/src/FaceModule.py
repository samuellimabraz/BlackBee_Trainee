#!/usr/bin/env python

import cv2
import cvzone
import mediapipe as mp
import math

deadZone = 95

# Face detector using the FaceMesh model by mediapipe
# Detect face and stipule a distance of the camera with focus distance
class FaceDetector:
    def __init__(
        self,
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5,
        focus_length=1000,
    ):
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        self.mp_face_mesh = mp.solutions.face_mesh

        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=max_num_faces,
            refine_landmarks=refine_landmarks,
            min_detection_confidence=min_detection_confidence,
            min_tracking_confidence=min_tracking_confidence,
        )

        self.focus_lenght = focus_length

    def detect_face(self, img, draw=False):
        ih, iw, _ = img.shape

        # To improve performance, optionally mark the image as not writeable to
        # pass by reference.
        img.flags.writeable = False
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(img)

        # Draw the face mesh annotations on the image.
        img.flags.writeable = True
        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)

        dist = 0
        bbox = 0
        event = 0
        if results.multi_face_landmarks:
            face = results.multi_face_landmarks[0].landmark

            # Calculete de distance of the people, 
            # with the distance of the eyes landmarks
            # x1, y1 = (face[145].x * iw, face[145].y * ih)
            # x2, y2 = (face[374].x * iw, face[374].y * ih)

            # w = math.hypot(x2 - x1, y2 - y1)

            # W = 6.3  # Real measure, distance of the eyes

            # # Finding distance to the camera, f = 640
            # # focus distance is a property of the camera
            # dist = int((W * self.focus_lenght) / w)

            # cvzone.putTextRect(
            #     img,
            #     f"Depth: {dist}cm",
            #     (0, 29),
            #     scale=2,
            # )

            # Creates a mesh and checks if the central point, the nose's landmark,
            # is within the central zone.
            # Generating events so that the camera
            # is centered with the face
            cx, cy = int(face[1].x * iw), int(face[1].y * ih)

            cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)

            if cx < iw // 2 - deadZone:
                event = 1
                cv2.putText(
                    img,
                    " GO LEFT ",
                    (20, 50),
                    cv2.FONT_HERSHEY_COMPLEX,
                    1,
                    (0, 0, 255),
                    3,
                )
                cv2.rectangle(
                    img,
                    (0, int(ih / 2 - deadZone)),
                    (int(iw / 2) - deadZone, int(ih / 2) + deadZone),
                    (0, 0, 255),
                    cv2.FILLED,
                )
            elif cx > int(iw / 2) + deadZone:
                event = 2
                cv2.putText(
                    img,
                    " GO RIGHT ",
                    (20, 50),
                    cv2.FONT_HERSHEY_COMPLEX,
                    1,
                    (0, 0, 255),
                    3,
                )
                cv2.rectangle(
                    img,
                    (int(iw / 2 + deadZone), int(ih / 2 - deadZone)),
                    (iw, int(ih / 2) + deadZone),
                    (0, 0, 255),
                    cv2.FILLED,
                )
            elif cy < int(ih / 2) - deadZone:
                event = 3
                cv2.putText(
                    img,
                    " GO UP ",
                    (20, 50),
                    cv2.FONT_HERSHEY_COMPLEX,
                    1,
                    (0, 0, 255),
                    3,
                )
                cv2.rectangle(
                    img,
                    (int(iw / 2 - deadZone), 0),
                    (int(iw / 2 + deadZone), int(ih / 2) - deadZone),
                    (0, 0, 255),
                    cv2.FILLED,
                )
            elif cy > int(ih / 2) + deadZone:
                event = 4
                cv2.putText(
                    img,
                    " GO DOWN ",
                    (20, 50),
                    cv2.FONT_HERSHEY_COMPLEX,
                    1,
                    (0, 0, 255),
                    3,
                )
                cv2.rectangle(
                    img,
                    (int(iw / 2 - deadZone), int(ih / 2) + deadZone),
                    (int(iw / 2 + deadZone), ih),
                    (0, 0, 255),
                    cv2.FILLED,
                )

            # cv2.line(
            #     img,
            #     (int(iw / 2), int(ih / 2)),
            #     (cx, cy),
            #     (0, 0, 255),
            #     3,
            # )

            # cv2.line(
            #     img,
            #     (int(iw / 2) - deadZone, 0),
            #     (int(iw / 2) - deadZone, ih),
            #     (255, 255, 0),
            #     3,
            # )
            # cv2.line(
            #     img,
            #     (int(iw / 2) + deadZone, 0),
            #     (int(iw / 2) + deadZone, ih),
            #     (255, 255, 0),
            #     3,
            # )
            # cv2.line(
            #     img,
            #     (0, int(ih / 2) - deadZone),
            #     (iw, int(ih / 2) - deadZone),
            #     (255, 255, 0),
            #     3,
            # )
            # cv2.line(
            #     img,
            #     (0, int(ih / 2) + deadZone),
            #     (iw, int(ih / 2) + deadZone),
            #     (255, 255, 0),
            #     3,
            # )

            # Find the indices of the peripheral points for the boundig box
            xmin, xmax = int(min(face, key=lambda l: l.x).x * iw), int(
                max(face, key=lambda l: l.x).x * iw
            )
            ymin, ymax = int(min(face, key=lambda l: l.y).y * ih), int(
                max(face, key=lambda l: l.y).y * ih
            )
            bbox = [xmin, ymin, xmax - xmin, ymax - ymin]

            if draw:
                self.draw_landmarks(img, results.multi_face_landmarks[0])

        return img, bbox, dist, event

    def draw_landmarks(self, img, face_landmarks):
        # Draw all 470 ladmarks and connections
        self.mp_drawing.draw_landmarks(
            image=img,
            landmark_list=face_landmarks,
            connections=self.mp_face_mesh.FACEMESH_TESSELATION,
            landmark_drawing_spec=None,
            connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_tesselation_style(),
        )
        self.mp_drawing.draw_landmarks(
            image=img,
            landmark_list=face_landmarks,
            connections=self.mp_face_mesh.FACEMESH_CONTOURS,
            landmark_drawing_spec=None,
            connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_contours_style(),
        )
        self.mp_drawing.draw_landmarks(
            image=img,
            landmark_list=face_landmarks,
            connections=self.mp_face_mesh.FACEMESH_IRISES,
            landmark_drawing_spec=None,
            connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_iris_connections_style(),
        )


from HandModule import MyHandDetector


def main():
    facedetector = FaceDetector(
        max_num_faces=1,
        refine_landmarks=False,
        min_detection_confidence=0.8,
        min_tracking_confidence=0.8,
        focus_length=640,
    )
    handdetector = MyHandDetector(False, 1, 0.70, 0.7)

    cap = cv2.VideoCapture(0)

    while cap.isOpened():
        success, frame = cap.read()
        iw, ih, _ = frame.shape
        frame = cv2.resize(frame, (iw, ih))

        if not success:
            continue

        frame, bbox, dist, event = facedetector.detect_face(frame, False)

        if dist > 0:
            # Area de reconhecimento para as m√£os
            x, y, w, h = (
                abs(bbox[0] - 220),
                abs(bbox[1]),
                abs(bbox[2] + 80),
                abs(bbox[3] + 70),
            )
            imgDetect = frame[y : (y + h), x : (x + w)]
            cvzone.cornerRect(frame, [x, y, w, h])
            event = handdetector.gestureRecognizer(imgDetect, (20, 20))

        cv2.imshow("MediaPipe Face Mesh", frame)

        if cv2.waitKey(2) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
